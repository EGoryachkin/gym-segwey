{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REINFORCE in pytorch (5 pts)\n",
    "\n",
    "Just like we did before for q-learning, this time we'll design a pytorch network to learn `CartPole-v0` via policy gradient (REINFORCE).\n",
    "\n",
    "Most of the code in this notebook is taken from approximate qlearning, so you'll find it more or less familiar and even simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring20/setup_colab.sh -O- | bash\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5b4fcfb518>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "env.reset()\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the network for REINFORCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For REINFORCE algorithm, we'll need a model that predicts action probabilities given states. Let's define such a model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple neural network that predicts policy logits. \n",
    "# Keep it simple: CartPole isn't worth deep architectures.\n",
    "model = nn.Sequential(nn.Linear(env.observation_space.shape[0], 100),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(100, 100),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(100, env.action_space.n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: output value of this function is not a torch tensor, it's a numpy array.\n",
    "So, here gradient calculation is not needed.\n",
    "<br>\n",
    "Use [no_grad](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad)\n",
    "to suppress gradient calculation.\n",
    "<br>\n",
    "Also, `.detach()` (or legacy `.data` property) can be used instead, but there is a difference:\n",
    "<br>\n",
    "With `.detach()` computational graph is built but then disconnected from a particular tensor,\n",
    "so `.detach()` should be used if that graph is needed for backprop via some other (not detached) tensor;\n",
    "<br>\n",
    "In contrast, no graph is built by any operation in `no_grad()` context, thus it's preferable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probs(states):\n",
    "    \"\"\" \n",
    "    Predict action probabilities given states.\n",
    "    :param states: numpy array of shape [batch, state_shape]\n",
    "    :returns: numpy array of shape [batch, n_actions]\n",
    "    \"\"\"\n",
    "    states = torch.autograd.Variable(torch.FloatTensor(states))\n",
    "    probas = torch.nn.functional.softmax(model.forward(states))\n",
    "    return probas.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_states = np.array([env.reset() for _ in range(5)])\n",
    "test_probas = predict_probs(test_states)\n",
    "assert isinstance(\n",
    "    test_probas, np.ndarray), \"you must return np array and not %s\" % type(test_probas)\n",
    "assert tuple(test_probas.shape) == (\n",
    "    test_states.shape[0], env.action_space.n), \"wrong output shape: %s\" % np.shape(test_probas)\n",
    "assert np.allclose(np.sum(test_probas, axis=1),\n",
    "                   1), \"probabilities do not sum to 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play the game\n",
    "\n",
    "We can now use our newly built agent to play the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_session(env, t_max=1000):\n",
    "    \"\"\" \n",
    "    play a full session with REINFORCE agent and train at the session end.\n",
    "    returns sequences of states, actions andrewards\n",
    "    \"\"\"\n",
    "    # arrays to record session\n",
    "    states, actions, rewards = [], [], []\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "        # action probabilities array aka pi(a|s)\n",
    "        action_probs = predict_probs(np.array([s]))[0]\n",
    "\n",
    "        # Sample action with given probabilities.\n",
    "        a = np.random.choice(env.action_space.n, p=action_probs)\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record session history to train later\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# test it\n",
    "states, actions, rewards = generate_session(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing cumulative rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumulative_rewards(rewards,  # rewards at each step\n",
    "                           gamma=0.99  # discount for reward\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    take a list of immediate rewards r(s,a) for the whole session \n",
    "    compute cumulative returns (a.k.a. G(s,a) in Sutton '16)\n",
    "    G_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
    "\n",
    "    The simple way to compute cumulative rewards is to iterate from last to first time tick\n",
    "    and compute G_t = r_t + gamma*G_{t+1} recurrently\n",
    "\n",
    "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
    "    \"\"\"\n",
    "    G = [rewards[-1]]\n",
    "    for gt in rewards[-2::-1]:\n",
    "        G.insert(0, gt + gamma*G[0])\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looks good!\n"
     ]
    }
   ],
   "source": [
    "get_cumulative_rewards(rewards)\n",
    "assert len(get_cumulative_rewards(list(range(100)))) == 100\n",
    "assert np.allclose(get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9), [\n",
    "                   1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n",
    "assert np.allclose(get_cumulative_rewards(\n",
    "    [0, 0, 1, -2, 3, -4, 0], gamma=0.5), [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n",
    "assert np.allclose(get_cumulative_rewards(\n",
    "    [0, 0, 1, 2, 3, 4, 0], gamma=0), [0, 0, 1, 2, 3, 4, 0])\n",
    "print(\"looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function and updates\n",
    "\n",
    "We now need to define objective and update over policy gradient.\n",
    "\n",
    "Our objective function is\n",
    "\n",
    "$$ J \\approx  { 1 \\over T } \\sum_{i=1}^T  G(s_i,a_i) $$\n",
    "\n",
    "\n",
    "Following the REINFORCE algorithm, we can define our objective as follows: \n",
    "\n",
    "$$ \\hat J \\approx { 1 \\over T } \\sum_{i=1}^T \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G(s_i,a_i) $$\n",
    "\n",
    "Entropy Regularizer\n",
    "  $$ H = - {1 \\over T} \\sum_{i=1}^T  \\sum_{a \\in A} {\\pi_\\theta(a|s_i) \\cdot \\log \\pi_\\theta(a|s_i)}$$\n",
    "\n",
    "$T$ is session length\n",
    "\n",
    "So we optimize a linear combination of $- \\hat J$, $-H$\n",
    "\n",
    "When you compute gradient of that function over network weights $ \\theta $, it will become exactly the policy gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y_tensor, ndims):\n",
    "    \"\"\" helper: take an integer vector and convert it to 1-hot matrix. \"\"\"\n",
    "    y_tensor = y_tensor.type(torch.LongTensor).view(-1, 1)\n",
    "    y_one_hot = torch.zeros(\n",
    "        y_tensor.size()[0], ndims).scatter_(1, y_tensor, 1)\n",
    "    return y_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code: define optimizers\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "def train_on_session(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
    "    \"\"\"\n",
    "    Takes a sequence of states, actions and rewards produced by generate_session.\n",
    "    Updates agent's weights by following the policy gradient above.\n",
    "    Please use Adam optimizer with default parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # cast everything into torch tensors\n",
    "    states = torch.tensor(states, dtype=torch.float32)\n",
    "    actions = torch.tensor(actions, dtype=torch.int32)\n",
    "    cumulative_returns = np.array(get_cumulative_rewards(rewards, gamma))\n",
    "    cumulative_returns = torch.tensor(cumulative_returns, dtype=torch.float32)\n",
    "\n",
    "    # predict logits, probas and log-probas using an agent.\n",
    "    logits = model(states)\n",
    "    probs = nn.functional.softmax(logits, -1)\n",
    "    log_probs = nn.functional.log_softmax(logits, -1)\n",
    "\n",
    "    assert all(isinstance(v, torch.Tensor) for v in [logits, probs, log_probs]), \\\n",
    "        \"please use compute using torch tensors and don't use predict_probs function\"\n",
    "\n",
    "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
    "    log_probs_for_actions = torch.sum(\n",
    "        log_probs * to_one_hot(actions, env.action_space.n), dim=1)\n",
    "   \n",
    "    # Compute loss here. Don't forgen entropy regularization with `entropy_coef` \n",
    "    J = torch.mean(log_probs_for_actions * cumulative_returns)\n",
    "    entropy = - torch.mean(torch.sum(probs * log_probs, -1))\n",
    "    loss = -J - 0.5*entropy\n",
    "    \n",
    "    # Gradient descent step\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    # technical: return session rewards to print them later\n",
    "    return np.sum(rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward:23.270\n",
      "mean reward:36.500\n",
      "mean reward:39.710\n",
      "mean reward:86.290\n",
      "mean reward:141.760\n",
      "mean reward:128.310\n",
      "mean reward:83.920\n",
      "mean reward:75.400\n",
      "mean reward:426.750\n",
      "mean reward:74.590\n",
      "mean reward:391.960\n",
      "mean reward:473.400\n",
      "mean reward:236.680\n",
      "mean reward:199.870\n",
      "mean reward:790.300\n",
      "You Win!\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    rewards = [train_on_session(*generate_session(env))\n",
    "               for _ in range(100)]  # generate new sessions\n",
    "    print(\"mean reward:%.3f\" % (np.mean(rewards)))\n",
    "    if np.mean(rewards) > 500:\n",
    "        print(\"You Win!\")  # but you can train even further\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1440, -0.1846], grad_fn=<AddBackward0>)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egor/.local/lib/python3.5/site-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/egor/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5afd7f7128>,\n",
       " <matplotlib.lines.Line2D at 0x7f5afd7f1940>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "state = env.reset()\n",
    "X = []\n",
    "i = 0\n",
    "while i < 500:\n",
    "    a = np.argmax(nn.functional.softmax(model(torch.tensor(state, dtype=torch.float32))).data.numpy())\n",
    "    state, r, done, _ = env.step(a)\n",
    "    X.append(state)\n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "plt.plot(range(len(X)),np.array(X)[:,[0,2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
